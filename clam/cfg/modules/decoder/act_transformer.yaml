# @package decoder

name: act_transformer
n_decoder_layers: 3
n_layers: 3
dim_model: 256
dim_feedforward: 2048
n_heads: 4
dropout: 0.1
pre_norm: False
feedforward_activation: gelu
seq_len: ${data.seq_len}

pos_enc: learned